{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm \n",
    "import optuna"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-12-25T07:29:42.383250Z",
     "iopub.execute_input": "2022-12-25T07:29:42.383699Z",
     "iopub.status.idle": "2022-12-25T07:29:48.315698Z",
     "shell.execute_reply.started": "2022-12-25T07:29:42.383623Z",
     "shell.execute_reply": "2022-12-25T07:29:48.314615Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, dataset, bert_tokenizer, gpt_tokenizer, bert_device, gpt_device):\n",
    "        super(Seq2SeqDataset, self).__init__()\n",
    "        \n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        self.gpt_tokenizer = gpt_tokenizer\n",
    "        self.bert_device = bert_device\n",
    "        self.gpt_device = gpt_device\n",
    "        \n",
    "        self.sent1, self.sent2 = self.create_pair_dataset(dataset)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        bert_sent1 = self.bert_tokenizer(self.sent1[i], padding='max_length', truncation=True, return_tensors='pt')\n",
    "        gpt_sent2 = self.gpt_tokenizer(self.sent2[i], padding='max_length', truncation=True, return_tensors='pt')\n",
    "        \n",
    "        bert_sent1 = {k: v.squeeze().to(self.bert_device) for k, v in bert_sent1.items()}\n",
    "        gpt_sent2 = {k: v.squeeze().to(self.gpt_device) for k, v in gpt_sent2.items()}\n",
    "        \n",
    "        return bert_sent1, gpt_sent2\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sent1)\n",
    "    \n",
    "    def create_tokenized_pairs(self, x):\n",
    "        sentences = re.split(r'[\\s]*#Person\\d#: ', x['dialogue'])[1:]\n",
    "\n",
    "        sentences1 = sentences[:-1]\n",
    "        sentences2 = list(map(lambda x: self.gpt_tokenizer.bos_token + x + self.gpt_tokenizer.eos_token, sentences[1:]))\n",
    "\n",
    "        return {'sent1': sentences1, 'sent2': sentences2}\n",
    "    \n",
    "    def create_pair_dataset(self, dataset):\n",
    "        tokenized_dataset = dataset.map(self.create_tokenized_pairs)\n",
    "\n",
    "        flatten_sent1 = [sent for sents in tokenized_dataset['sent1'] for sent in sents]\n",
    "        flatten_sent2 = [sent for sents in tokenized_dataset['sent2'] for sent in sents]\n",
    "\n",
    "        return flatten_sent1, flatten_sent2\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-25T07:29:48.317848Z",
     "iopub.execute_input": "2022-12-25T07:29:48.318492Z",
     "iopub.status.idle": "2022-12-25T07:29:48.459849Z",
     "shell.execute_reply.started": "2022-12-25T07:29:48.318448Z",
     "shell.execute_reply": "2022-12-25T07:29:48.458789Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_bert_model_tokenizer(path, model_max_length, bert_device):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path, model_max_length=model_max_length)\n",
    "    model = AutoModel.from_pretrained(path)\n",
    "    \n",
    "    return model.to(bert_device), tokenizer\n",
    "\n",
    "\n",
    "def get_gpt_model_tokenizer(path, model_max_length, gpt_device):\n",
    "    special_tokens = {'bos_token': '<BOS>', 'eos_token': '<EOS>', \n",
    "                      'unk_token': '<UNK>', 'pad_token': '<PAD>'}\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(path, model_max_length=model_max_length)\n",
    "    tokenizer.add_special_tokens(special_tokens)\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(path, add_cross_attention=True)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.add_cross_attention = True\n",
    "    model.config.is_decoder = True\n",
    "    \n",
    "    return model.to(gpt_device), tokenizer\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-25T07:29:48.461392Z",
     "iopub.execute_input": "2022-12-25T07:29:48.462036Z",
     "iopub.status.idle": "2022-12-25T07:29:48.480996Z",
     "shell.execute_reply.started": "2022-12-25T07:29:48.462000Z",
     "shell.execute_reply": "2022-12-25T07:29:48.479945Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_dataloader(bs, bert_tokenizer, gpt_tokenizer, bert_device, gpt_device):\n",
    "    train_data = load_dataset('knkarthick/dialogsum', split='train')\n",
    "    val_data = load_dataset('knkarthick/dialogsum', split='validation')\n",
    "\n",
    "    train_dataset = Seq2SeqDataset(train_data, bert_tokenizer, gpt_tokenizer, bert_device, gpt_device)\n",
    "    val_dataset = Seq2SeqDataset(val_data, bert_tokenizer, gpt_tokenizer, bert_device, gpt_device)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=bs, shuffle=True)\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-25T07:29:48.484523Z",
     "iopub.execute_input": "2022-12-25T07:29:48.484969Z",
     "iopub.status.idle": "2022-12-25T07:29:48.498288Z",
     "shell.execute_reply.started": "2022-12-25T07:29:48.484932Z",
     "shell.execute_reply": "2022-12-25T07:29:48.496970Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Seq2SeqModel:\n",
    "    def __init__(self, bert_model, gpt_model, bert_tokenizer, gpt_tokenizer):\n",
    "        self.bert_model = bert_model\n",
    "        self.gpt_model = gpt_model\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        self.gpt_tokenizer = gpt_tokenizer\n",
    "        \n",
    "    def train_step(self, dataloader, optimizer):\n",
    "        self.bert_model.train(), self.gpt_model.train()\n",
    "        losses = []\n",
    "\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, (x, y) in enumerate(pbar):\n",
    "            optimizer.zero_grad()\n",
    "            bert_out = self.bert_model(**x)\n",
    "            gpt_out = self.gpt_model(**y, labels=y['input_ids'], \n",
    "                                     encoder_hidden_states=bert_out.last_hidden_state.to(self.gpt_model.device))\n",
    "            loss = gpt_out.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_description(f'Batch Loss: {np.mean(losses):.5f}')\n",
    "        \n",
    "        return np.mean(losses)\n",
    "        \n",
    "    def eval_step(self, dataloader):\n",
    "        self.bert_model.eval(), self.gpt_model.eval()\n",
    "        losses = []\n",
    "\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, (x, y) in enumerate(pbar):\n",
    "            bert_out = self.bert_model(**x)\n",
    "            gpt_out = self.gpt_model(**y, labels=y['input_ids'], \n",
    "                                     encoder_hidden_states=bert_out.last_hidden_state.to(self.gpt_model.device))\n",
    "            loss = gpt_out.loss\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_description(f'Batch Loss: {np.mean(losses):.5f}')\n",
    "        \n",
    "        return np.mean(losses)\n",
    "    \n",
    "    def answer(self, sent):\n",
    "        with torch.no_grad():\n",
    "            tokenized_sent = self.bert_tokenizer(sent, padding='max_length', \n",
    "                                                 truncation=True, return_tensors='pt')\n",
    "            tokenized_ans = self.gpt_tokenizer(self.gpt_tokenizer.bos_token, return_tensors='pt')\n",
    "\n",
    "            tokenized_sent = {k: v.to(self.bert_model.device) for k, v in tokenized_sent.items()}\n",
    "            tokenized_ans = {k: v.to(self.gpt_model.device) for k, v in tokenized_ans.items()}\n",
    "            \n",
    "            bert_out = self.bert_model(**tokenized_sent)\n",
    "            gpt_out = self.gpt_model.generate(**tokenized_ans, max_new_tokens=30, temperature=0.9, \n",
    "                                              encoder_hidden_state=bert_out.last_hidden_state)\n",
    "\n",
    "            return self.gpt_tokenizer.decode(gpt_out[0])\n",
    "\n",
    "    def save(self, model_dir):\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        self.bert_model.save_pretrained(os.path.join(model_dir, 'bert_encoder'))\n",
    "        self.gpt_model.save_pretrained(os.path.join(model_dir, 'gpt_decoder'))\n",
    "        "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-25T07:29:48.500478Z",
     "iopub.execute_input": "2022-12-25T07:29:48.501078Z",
     "iopub.status.idle": "2022-12-25T07:29:48.518733Z",
     "shell.execute_reply.started": "2022-12-25T07:29:48.501042Z",
     "shell.execute_reply": "2022-12-25T07:29:48.517894Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(max_len, epochs, bs, lr, bert_device, gpt_device, model_path):\n",
    "    bert_encoder, bert_tokenizer = get_bert_model_tokenizer('bert-base-cased', max_len, bert_device)\n",
    "    gpt_decoder, gpt_tokenizer = get_gpt_model_tokenizer('gpt2', max_len, gpt_device)\n",
    "\n",
    "    train_loader, val_loader = get_dataloader(bs, bert_tokenizer, gpt_tokenizer, bert_device, gpt_device)\n",
    "    opt = optim.Adam(chain(gpt_decoder.parameters(), bert_encoder.parameters()), lr=lr)\n",
    "\n",
    "    seq2seq_model = Seq2SeqModel(bert_encoder, gpt_decoder, bert_tokenizer, gpt_tokenizer)\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        train_loss = seq2seq_model.train_step(train_loader, opt)\n",
    "        val_loss = seq2seq_model.eval_step(val_loader)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "                \n",
    "        plt.plot(train_losses, 'b', label='Training losses')\n",
    "        plt.plot(val_losses, 'r', label='Validation losses')\n",
    "        plt.show()\n",
    "        \n",
    "        seq2seq_model.save(f'{model_path}_{val_loss}')\n",
    "        \n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    #return val_loss\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-25T07:30:20.431380Z",
     "iopub.execute_input": "2022-12-25T07:30:20.431989Z",
     "iopub.status.idle": "2022-12-25T07:30:20.440931Z",
     "shell.execute_reply.started": "2022-12-25T07:30:20.431952Z",
     "shell.execute_reply": "2022-12-25T07:30:20.440007Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train(max_len=50, bert_device=torch.device('cuda:0'), gpt_device=torch.device('cuda:1'), \n",
    "      model_path=f'epoch_loss', bs=3, lr=2.545263049508698e-05, epochs=10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-25T07:30:23.503069Z",
     "iopub.execute_input": "2022-12-25T07:30:23.504108Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/35280 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c8981f4ade242c58247800d0bf826ae"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "whi"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! zip -r bert_gpt.zip /kaggle/working/epoch_loss_1.0249150006171202"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-25T18:24:42.412526Z",
     "iopub.execute_input": "2022-12-25T18:24:42.412905Z",
     "iopub.status.idle": "2022-12-25T18:25:41.170341Z",
     "shell.execute_reply.started": "2022-12-25T18:24:42.412875Z",
     "shell.execute_reply": "2022-12-25T18:25:41.169182Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "  adding: kaggle/working/epoch_loss_1.0249150006171202/ (stored 0%)\n  adding: kaggle/working/epoch_loss_1.0249150006171202/gpt_decoder/ (stored 0%)\n  adding: kaggle/working/epoch_loss_1.0249150006171202/gpt_decoder/config.json (deflated 52%)\n  adding: kaggle/working/epoch_loss_1.0249150006171202/gpt_decoder/pytorch_model.bin (deflated 11%)\n  adding: kaggle/working/epoch_loss_1.0249150006171202/bert_encoder/ (stored 0%)\n  adding: kaggle/working/epoch_loss_1.0249150006171202/bert_encoder/config.json (deflated 48%)\n  adding: kaggle/working/epoch_loss_1.0249150006171202/bert_encoder/pytorch_model.bin (deflated 7%)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    params = {'bs': trial.suggest_int('bs', 2, 6),\n",
    "              'lr': trial.suggest_float('lr', 1e-5, 1e-2, log=True)}    \n",
    "    \n",
    "    return train(max_len=50, bert_device=torch.device('cuda:0'), \n",
    "                 gpt_device=torch.device('cuda:1'), model_path=f'trial{trial.number}', **params)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-19T10:48:10.288087Z",
     "iopub.execute_input": "2022-12-19T10:48:10.288490Z",
     "iopub.status.idle": "2022-12-19T10:48:10.294208Z",
     "shell.execute_reply.started": "2022-12-19T10:48:10.288447Z",
     "shell.execute_reply": "2022-12-19T10:48:10.292998Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=6)\n",
    "print(study.best_params)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-19T10:54:43.559287Z",
     "iopub.execute_input": "2022-12-19T10:54:43.559975Z",
     "iopub.status.idle": "2022-12-19T18:08:46.167218Z",
     "shell.execute_reply.started": "2022-12-19T10:54:43.559940Z",
     "shell.execute_reply": "2022-12-19T18:08:46.164621Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "text": "\u001B[32m[I 2022-12-19 10:54:43,561]\u001B[0m A new study created in memory with name: no-name-a98f1eea-e4d5-418f-ab3f-4fe285a8a39c\u001B[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.1.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.bias', 'h.2.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.0.ln_cross_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.bias', 'h.0.crossattention.masked_bias', 'h.0.crossattention.q_attn.weight', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.2.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.8.crossattention.masked_bias', 'h.4.ln_cross_attn.weight', 'h.9.crossattention.bias', 'h.7.ln_cross_attn.weight', 'h.1.crossattention.masked_bias', 'h.5.crossattention.bias', 'h.1.crossattention.c_proj.weight', 'h.7.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.11.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.bias', 'h.4.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.10.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.5.ln_cross_attn.weight', 'h.2.crossattention.masked_bias', 'h.2.crossattention.c_proj.weight', 'h.6.crossattention.bias', 'h.10.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.11.ln_cross_attn.weight', 'h.6.ln_cross_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.2.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.bias', 'h.5.crossattention.masked_bias', 'h.6.crossattention.q_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.10.crossattention.bias', 'h.3.ln_cross_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.1.crossattention.bias', 'h.5.crossattention.c_attn.weight', 'h.4.crossattention.bias', 'h.3.crossattention.bias', 'h.8.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.weight', 'h.3.crossattention.masked_bias', 'h.8.crossattention.c_proj.bias', 'h.11.crossattention.masked_bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/12460 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "992abcebec15434bac80a4851c46aadd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7127600ea8b44e708366537f10ace38f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/26460 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1f425d096f0474dbbfb8ca188850e67"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1048 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35a44b31dbea4cc6b1496dad6170147c"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[32m[I 2022-12-19 12:04:52,292]\u001B[0m Trial 0 finished with value: 1.081597953366528 and parameters: {'bs': 4, 'lr': 0.00021735438243198512}. Best is trial 0 with value: 1.081597953366528.\u001B[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.1.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.bias', 'h.2.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.0.ln_cross_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.bias', 'h.0.crossattention.masked_bias', 'h.0.crossattention.q_attn.weight', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.2.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.8.crossattention.masked_bias', 'h.4.ln_cross_attn.weight', 'h.9.crossattention.bias', 'h.7.ln_cross_attn.weight', 'h.1.crossattention.masked_bias', 'h.5.crossattention.bias', 'h.1.crossattention.c_proj.weight', 'h.7.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.11.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.bias', 'h.4.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.10.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.5.ln_cross_attn.weight', 'h.2.crossattention.masked_bias', 'h.2.crossattention.c_proj.weight', 'h.6.crossattention.bias', 'h.10.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.11.ln_cross_attn.weight', 'h.6.ln_cross_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.2.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.bias', 'h.5.crossattention.masked_bias', 'h.6.crossattention.q_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.10.crossattention.bias', 'h.3.ln_cross_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.1.crossattention.bias', 'h.5.crossattention.c_attn.weight', 'h.4.crossattention.bias', 'h.3.crossattention.bias', 'h.8.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.weight', 'h.3.crossattention.masked_bias', 'h.8.crossattention.c_proj.bias', 'h.11.crossattention.masked_bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/12460 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d12d6a2b7fa429e96e1e5b930b2a930"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4809e555cee4a61885396aedf4ebe60"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/26460 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c746829744c848689566b1cddd384815"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1048 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4eed9ab90d74c67b52d53cd0e7e327f"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[32m[I 2022-12-19 13:14:31,988]\u001B[0m Trial 1 finished with value: 1.3879430635000458 and parameters: {'bs': 4, 'lr': 0.0009823185580343666}. Best is trial 0 with value: 1.081597953366528.\u001B[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.1.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.bias', 'h.2.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.0.ln_cross_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.bias', 'h.0.crossattention.masked_bias', 'h.0.crossattention.q_attn.weight', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.2.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.8.crossattention.masked_bias', 'h.4.ln_cross_attn.weight', 'h.9.crossattention.bias', 'h.7.ln_cross_attn.weight', 'h.1.crossattention.masked_bias', 'h.5.crossattention.bias', 'h.1.crossattention.c_proj.weight', 'h.7.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.11.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.bias', 'h.4.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.10.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.5.ln_cross_attn.weight', 'h.2.crossattention.masked_bias', 'h.2.crossattention.c_proj.weight', 'h.6.crossattention.bias', 'h.10.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.11.ln_cross_attn.weight', 'h.6.ln_cross_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.2.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.bias', 'h.5.crossattention.masked_bias', 'h.6.crossattention.q_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.10.crossattention.bias', 'h.3.ln_cross_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.1.crossattention.bias', 'h.5.crossattention.c_attn.weight', 'h.4.crossattention.bias', 'h.3.crossattention.bias', 'h.8.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.weight', 'h.3.crossattention.masked_bias', 'h.8.crossattention.c_proj.bias', 'h.11.crossattention.masked_bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/12460 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7208a501b0c14e5d8bb043174e45e4bb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2e60c60171b43d2b6694ca3ab541a6a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/17640 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b85d894cae8447c8cfa332c1e2ed443"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/699 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc3ec989f3214bcb8df148bd9b0ef263"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[32m[I 2022-12-19 14:08:32,026]\u001B[0m Trial 2 finished with value: 1.4328137665603293 and parameters: {'bs': 6, 'lr': 0.0019448383663810552}. Best is trial 0 with value: 1.081597953366528.\u001B[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.1.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.bias', 'h.2.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.0.ln_cross_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.bias', 'h.0.crossattention.masked_bias', 'h.0.crossattention.q_attn.weight', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.2.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.8.crossattention.masked_bias', 'h.4.ln_cross_attn.weight', 'h.9.crossattention.bias', 'h.7.ln_cross_attn.weight', 'h.1.crossattention.masked_bias', 'h.5.crossattention.bias', 'h.1.crossattention.c_proj.weight', 'h.7.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.11.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.bias', 'h.4.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.10.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.5.ln_cross_attn.weight', 'h.2.crossattention.masked_bias', 'h.2.crossattention.c_proj.weight', 'h.6.crossattention.bias', 'h.10.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.11.ln_cross_attn.weight', 'h.6.ln_cross_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.2.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.bias', 'h.5.crossattention.masked_bias', 'h.6.crossattention.q_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.10.crossattention.bias', 'h.3.ln_cross_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.1.crossattention.bias', 'h.5.crossattention.c_attn.weight', 'h.4.crossattention.bias', 'h.3.crossattention.bias', 'h.8.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.weight', 'h.3.crossattention.masked_bias', 'h.8.crossattention.c_proj.bias', 'h.11.crossattention.masked_bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/12460 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e99a46255864c69942a51950f1f310a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d643d8b0bf62442daf1ee151830bc203"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/26460 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e37d4bd2b52f4629903d5bb72b466aa5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1048 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f72e7acb7902435e9dffe7766e521a33"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[32m[I 2022-12-19 15:18:19,919]\u001B[0m Trial 3 finished with value: 1.4516949300433843 and parameters: {'bs': 4, 'lr': 0.001055327980234386}. Best is trial 0 with value: 1.081597953366528.\u001B[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.1.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.bias', 'h.2.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.0.ln_cross_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.bias', 'h.0.crossattention.masked_bias', 'h.0.crossattention.q_attn.weight', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.2.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.8.crossattention.masked_bias', 'h.4.ln_cross_attn.weight', 'h.9.crossattention.bias', 'h.7.ln_cross_attn.weight', 'h.1.crossattention.masked_bias', 'h.5.crossattention.bias', 'h.1.crossattention.c_proj.weight', 'h.7.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.11.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.bias', 'h.4.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.10.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.5.ln_cross_attn.weight', 'h.2.crossattention.masked_bias', 'h.2.crossattention.c_proj.weight', 'h.6.crossattention.bias', 'h.10.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.11.ln_cross_attn.weight', 'h.6.ln_cross_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.2.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.bias', 'h.5.crossattention.masked_bias', 'h.6.crossattention.q_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.10.crossattention.bias', 'h.3.ln_cross_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.1.crossattention.bias', 'h.5.crossattention.c_attn.weight', 'h.4.crossattention.bias', 'h.3.crossattention.bias', 'h.8.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.weight', 'h.3.crossattention.masked_bias', 'h.8.crossattention.c_proj.bias', 'h.11.crossattention.masked_bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/12460 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd57dde45c354e4981dddd317289fdef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f668b2d9381344dd88164f58a25a8db7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/35280 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a119521d915449dac067126fdcc1910"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1397 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2638b539d72a451a8011e9167ef72eb4"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[32m[I 2022-12-19 16:43:42,976]\u001B[0m Trial 4 finished with value: 0.9833395414123727 and parameters: {'bs': 3, 'lr': 2.545263049508698e-05}. Best is trial 4 with value: 0.9833395414123727.\u001B[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.1.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.bias', 'h.2.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.0.ln_cross_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.bias', 'h.0.crossattention.masked_bias', 'h.0.crossattention.q_attn.weight', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.2.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.8.crossattention.masked_bias', 'h.4.ln_cross_attn.weight', 'h.9.crossattention.bias', 'h.7.ln_cross_attn.weight', 'h.1.crossattention.masked_bias', 'h.5.crossattention.bias', 'h.1.crossattention.c_proj.weight', 'h.7.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.11.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.bias', 'h.4.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.10.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.5.ln_cross_attn.weight', 'h.2.crossattention.masked_bias', 'h.2.crossattention.c_proj.weight', 'h.6.crossattention.bias', 'h.10.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.11.ln_cross_attn.weight', 'h.6.ln_cross_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.2.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.bias', 'h.5.crossattention.masked_bias', 'h.6.crossattention.q_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.10.crossattention.bias', 'h.3.ln_cross_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.1.crossattention.bias', 'h.5.crossattention.c_attn.weight', 'h.4.crossattention.bias', 'h.3.crossattention.bias', 'h.8.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.weight', 'h.3.crossattention.masked_bias', 'h.8.crossattention.c_proj.bias', 'h.11.crossattention.masked_bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/12460 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c526b982da94cf99d271dcc44ebc337"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c17647f02e247a2a7544ec3e3b69985"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/35280 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8ff9d0891ae47e299933ae09a851709"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1397 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92dadc969cff4b9c8bbd090564335365"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[32m[I 2022-12-19 18:08:46,160]\u001B[0m Trial 5 finished with value: 1.7344969805108708 and parameters: {'bs': 3, 'lr': 0.005516881543598113}. Best is trial 4 with value: 0.9833395414123727.\u001B[0m\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "{'bs': 3, 'lr': 2.545263049508698e-05}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! zip -r bert_gpt.zip /kaggle/working/trial4_0.9833395414123727"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-19T18:09:27.770168Z",
     "iopub.execute_input": "2022-12-19T18:09:27.770786Z",
     "iopub.status.idle": "2022-12-19T18:10:24.472132Z",
     "shell.execute_reply.started": "2022-12-19T18:09:27.770740Z",
     "shell.execute_reply": "2022-12-19T18:10:24.471093Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n  adding: kaggle/working/trial4_0.9833395414123727/ (stored 0%)\n  adding: kaggle/working/trial4_0.9833395414123727/bert_encoder/ (stored 0%)\n  adding: kaggle/working/trial4_0.9833395414123727/bert_encoder/pytorch_model.bin (deflated 7%)\n  adding: kaggle/working/trial4_0.9833395414123727/bert_encoder/config.json (deflated 48%)\n  adding: kaggle/working/trial4_0.9833395414123727/gpt_decoder/ (stored 0%)\n  adding: kaggle/working/trial4_0.9833395414123727/gpt_decoder/pytorch_model.bin (deflated 11%)\n  adding: kaggle/working/trial4_0.9833395414123727/gpt_decoder/config.json (deflated 52%)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    pass"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-17T21:05:56.284858Z",
     "iopub.execute_input": "2022-12-17T21:05:56.285272Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
